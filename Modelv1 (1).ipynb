{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modelv1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bf170ebb114d4b7d97aba697af3aa9d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "state": {
            "_view_name": "IntSliderView",
            "style": "IPY_MODEL_844bd6b0532940a5bb7587250110f241",
            "_dom_classes": [],
            "description": "",
            "step": 1,
            "_model_name": "IntSliderModel",
            "orientation": "horizontal",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "min": 0,
            "continuous_update": true,
            "readout_format": "d",
            "description_tooltip": null,
            "readout": true,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_90fdd06faf824e1caba936490b811ef0"
          }
        },
        "844bd6b0532940a5bb7587250110f241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "state": {
            "_view_name": "StyleView",
            "handle_color": null,
            "_model_name": "SliderStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "90fdd06faf824e1caba936490b811ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "N26IVBwOGWxN"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as plt\n",
        "import sys\n",
        "assert 'zipfile' in sys.modules\n",
        "import math\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# import the widgets module\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "\n",
        "import scipy.stats as ss\n",
        "from collections import Counter\n",
        "import warnings\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQJL8scdHMqH",
        "outputId": "638b83cc-a548-48a5-cb48-239f4c1f6c2a"
      },
      "source": [
        "link = 'https://drive.google.com/file/d/1xoZGzL7mbE4AgqoXCECgNqEXeYS8ZJ5P/view?usp=sharing'\n",
        "#fluff, id = link.split('=')\n",
        "id = '1xoZGzL7mbE4AgqoXCECgNqEXeYS8ZJ5P'\n",
        "print (id) # Verify that you have everything after '='\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('Audience_LA_DMA.csv')  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1xoZGzL7mbE4AgqoXCECgNqEXeYS8ZJ5P\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98T70a19GPAV"
      },
      "source": [
        "# MODEL PROTOTYPE V.1:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZNhpv8mhiz6"
      },
      "source": [
        "## The Narrative: \n",
        "Our product is a solution to an industry-wide dilemma of how to keep data unbiased once put through a workflow. We want to ensure that the data accurately represents the population of the datafied world. Our goal is to ultimately make a tool useful to Kinesso, and in general advertisement firms and their clients, who would want their actual audience pool to be wider and more representative of the intended audience.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "up76zreah6ne"
      },
      "source": [
        "## The Solution: \n",
        "\n",
        "A common fix to unbiasing the data is to keep on introducing new clean data. However, the data inevitably is sullied. Our solution tackles bias during the early stages of workflow, specifically during audience assembly. The product will accompany the SQL like workflow of Kinesso in building their audiences for campaigns, and alarm the user when there is potential bias in their audience selection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufogngjVzizW"
      },
      "source": [
        "EXAMPLE OF WORKFLOW WITH SOME EDA: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVc6UhQ_znAx"
      },
      "source": [
        "**disclaimer: the following scenario is a very simplified version of what actually happens in the real world** \n",
        "\n",
        "Our client Toyota asks us to help them run a campaign in LA. We go to our vast database and start building an audience. We start with a vast dataset of past log events with geographical information. \n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkJkje9RGWxW"
      },
      "source": [
        "df = pd.read_csv('Audience_LA_DMA.csv')\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rMTJYPLLuqO"
      },
      "source": [
        "df = df.replace('NaN',0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2smKXTC3B90"
      },
      "source": [
        "\n",
        "Toyota asked us to find clients that would be interested in buying their Toyota Siennas! We start by looking for households that own homes, and that approximatley earn on average,[ a yearly household income of $111,500](https://motorandwheels.com/11-toyota-sienna-statistics-facts/#:~:text=Sienna%20buyers%20are%20younger%20than,yearly%20household%20income%20of%20%24111%2C500)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fLwSpZmzea9"
      },
      "source": [
        "sienna= df[df['HOMEOWNERSHIP_STATUS'] == 'Homeowner']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QggoeuRMGwBA"
      },
      "source": [
        "len(df.index) - len(sienna.index) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOGLslMDHQB5"
      },
      "source": [
        "new_df = df[['ETHNICITY']]\n",
        "new_df['dataframe'] = 'df'\n",
        "new_df2 = sienna[['ETHNICITY']]\n",
        "new_df2['dataframe'] = 'sienna'\n",
        "combined = new_df.append(new_df2)\n",
        "combined\n",
        "\n",
        "sns.catplot(x = \"ETHNICITY\", kind=\"count\", hue = 'dataframe', data=combined) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d6b3qv_5v0F"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvO2G2vI58Sp"
      },
      "source": [
        "df.DEMO_HH_INCOME.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8B_113Cltk3"
      },
      "source": [
        "sienna_home= df[df['DEMO_HH_INCOME'] == '$100,000 to $149,999']\n",
        "sienna_home"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCOU6REQvoMm"
      },
      "source": [
        "new_df = sienna[['ETHNICITY']]\n",
        "new_df['dataframe'] = 'sienna'\n",
        "new_df2 = sienna_home[['ETHNICITY']]\n",
        "new_df2['dataframe'] = 'sienna_home'\n",
        "combined = new_df.append(new_df2)\n",
        "combined\n",
        "\n",
        "sns.catplot(x = \"ETHNICITY\", kind=\"count\", hue = 'dataframe', data=combined) \n",
        "len(new_df.index) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI1gK9yByJtl"
      },
      "source": [
        "This is where the bias can already take place. Toyota asked me to sell a car that is geared for family life, and so I selected those who have houses. This already discluded a good portion of people who could have afforded this car, but who don't have houses. This is where our tool would at this point, raise a red flag!\n",
        " \n",
        "The following EDA is done to highlight additional insights to induced bias, or general insights on our data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqtFfvty9PvW"
      },
      "source": [
        "### EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_GG76TaTDqF"
      },
      "source": [
        "fig_dims = (15, 4)\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "\n",
        "sns.countplot(x=\"DEMO_HH_INCOME\", order = ['Less than $30,000', '$30,000 to $49,999', '$50,000 to $74,999', '$75,000 to $99,999', '$100,000 to $149,999', '$150,000 to $199,999', '$200,000 to $249,999', '$250,000 +'], ax = ax, data=df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsFqsJbP4pT_"
      },
      "source": [
        "Simple count of how many people of each race are in each income bracket. All bars in each group should add to 100%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va79I_6_sOeJ"
      },
      "source": [
        "fig_dims = (15, 4)\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "sns.countplot(x=\"DEMO_HH_INCOME\", order = ['Less than $30,000', '$30,000 to $49,999', '$50,000 to $74,999', '$75,000 to $99,999', \n",
        "                                           '$100,000 to $149,999', '$150,000 to $199,999', '$200,000 to $249,999', \n",
        "                                           '$250,000 +'], hue = 'ETHNICITY',hue_order = ['White', 'Asian', 'Hispanic', 'African American'],  ax = ax, data=df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5WjHPf95Mt5"
      },
      "source": [
        "Normailzed count of how many people of each race are in each income bracket. All bars in each group should add to 100%. Sanity check - it should look very similar to the above graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "846K24U9sOg-"
      },
      "source": [
        "fig_dims = (15, 4)\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "\n",
        "#sns.set(color_codes=True)\n",
        "\n",
        "df_plot = df\n",
        "\n",
        "x,y = 'DEMO_HH_INCOME', 'ETHNICITY'\n",
        "\n",
        "df_plot = df_plot.groupby(x)[y].value_counts(normalize=True).mul(100).rename('percent').reset_index()\n",
        "\n",
        "sns.barplot(x=x, y='percent', hue=y, order = ['Less than $30,000', '$30,000 to $49,999',\n",
        "                                              '$50,000 to $74,999', '$75,000 to $99,999', '$100,000 to $149,999', \n",
        "                                              '$150,000 to $199,999', '$200,000 to $249,999', \n",
        "                                              '$250,000 +'], hue_order = ['White', 'Asian', 'Hispanic', 'African American'], ax=ax, data = df_plot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZlSoQSS5hts"
      },
      "source": [
        "Race by income - shows the percentage of people of a certain race who are in a certain bracket. All the bars for one race add to 100%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jwxAYxhsOqS"
      },
      "source": [
        "fig_dims = (15, 4)\n",
        "fig, ax = plt.subplots(figsize=fig_dims)\n",
        "\n",
        "df_plot = df\n",
        "\n",
        "x,y = 'ETHNICITY', 'DEMO_HH_INCOME'\n",
        "\n",
        "\n",
        "df_plot = df_plot.groupby(x)[y].value_counts(normalize=True).mul(100).rename('percent').reset_index()\n",
        "\n",
        "sns.barplot(x=y, y='percent', hue=x, order = ['Less than $30,000', '$30,000 to $49,999', \n",
        "                                              '$50,000 to $74,999', '$75,000 to $99,999', '$100,000 to $149,999', \n",
        "                                              '$150,000 to $199,999', '$200,000 to $249,999', \n",
        "                                              '$250,000 +'], hue_order = ['White', 'Asian', 'Hispanic', 'African American'],  ax=ax, data = df_plot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFyTKQ_-96VA"
      },
      "source": [
        "We plan to include a widget to this audience selection tool, which would alarm the user that one of the distributions have changed drastically. In this example, the African American population has been drastically discluded.\n",
        "We will accomplish the flagging by finding ways to measure entropy of distributions, after applying constraints on a feature. This would require us to find a method of computing entropy for each data type. For example, once I would apply the “$100,000 to $149,999”  to income level, I would use “Earth Mover’s Distance” to see how drastically each distribution changed thereafter.\n",
        " \n",
        "Moreover, given the constraints of the time,while we will be able to flag large shifts in the distributions once changes are made to them in the audience selection process, we will be unable to make an actual model that can tell that the huge \"shift\" is biased. Thus, our product can help flag for bias, but won't be able to distinguish what it is.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B2jp-kxqCs4"
      },
      "source": [
        "widgets.Dropdown(\n",
        "    options=['Pie Chart', 'Bar graph', 'scatterplot'],\n",
        "    value='Bar graph',\n",
        "    description='Graph Type:',\n",
        "    disabled=False\n",
        "\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x1oROIIo5zZ"
      },
      "source": [
        "# Conditional Entropy and Correlational Heatmaps \n",
        "\n",
        "\n",
        "Here we take a deeper dive into the relationships between the various features in our data. To do so, we use the entropy between the variables to innvestigate a few statistics that are similar to correlation coefficients, but are adjusted for categorical data. \n",
        "\n",
        "credits to Shaked Zychlinski for providing us with preliminary code to explore these relationships.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eePduuFaBYeI"
      },
      "source": [
        "df2 = df\n",
        "df2 = df2.rename(columns = {'ETHNICITY': 'RACE', 'Unnamed: 0':'ID'})\n",
        "df2['ZIP'] = df2['ZIP'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baxTmZ5PBZpg"
      },
      "source": [
        "_REPLACE = 'replace'\n",
        "_DEFAULT_REPLACE_VALUE = 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYJl22KXBRLf"
      },
      "source": [
        "def replace_nan_with_value(x, y, value):\n",
        "    x = np.array([v if v == v and v is not None else value for v in x])  # NaN != NaN\n",
        "    y = np.array([v if v == v and v is not None else value for v in y])\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5cROtGgBRet"
      },
      "source": [
        "def remove_incomplete_samples(x, y):\n",
        "    x = [v if v is not None else np.nan for v in x]\n",
        "    y = [v if v is not None else np.nan for v in y]\n",
        "    arr = np.array([x, y]).transpose()\n",
        "    arr = arr[~np.isnan(arr).any(axis=1)].transpose()\n",
        "    if isinstance(x, list):\n",
        "        return arr[0].tolist(), arr[1].tolist()\n",
        "    else:\n",
        "        return arr[0], arr[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQAvdMRyGWxf"
      },
      "source": [
        "def conditional_entropy(x,y,\n",
        "                        nan_strategy=_REPLACE,\n",
        "                        nan_replace_value=_DEFAULT_REPLACE_VALUE,\n",
        "                        log_base: float = math.e):\n",
        "    \"\"\"\n",
        "    Calculates the conditional entropy of x given y: S(x|y)\n",
        "    Wikipedia: https://en.wikipedia.org/wiki/Conditional_entropy\n",
        "    Parameters:\n",
        "    -----------\n",
        "    x : list / NumPy ndarray / Pandas Series\n",
        "        A sequence of measurements\n",
        "    y : list / NumPy ndarray / Pandas Series\n",
        "        A sequence of measurements\n",
        "    nan_strategy : string, default = 'replace'\n",
        "        How to handle missing values: can be either 'drop' to remove samples\n",
        "        with missing values, or 'replace' to replace all missing values with\n",
        "        the nan_replace_value. Missing values are None and np.nan.\n",
        "    nan_replace_value : any, default = 0.0\n",
        "        The value used to replace missing values with. Only applicable when\n",
        "        nan_strategy is set to 'replace'.\n",
        "    log_base: float, default = e\n",
        "        specifying base for calculating entropy. Default is base e.\n",
        "    Returns:\n",
        "    --------\n",
        "    float\n",
        "    \"\"\"\n",
        "    if nan_strategy == _REPLACE:\n",
        "        x, y = replace_nan_with_value(x, y, nan_replace_value)\n",
        "    elif nan_strategy == _DROP:\n",
        "        x, y = remove_incomplete_samples(x, y)\n",
        "    y_counter = Counter(y)\n",
        "    xy_counter = Counter(list(zip(x, y)))\n",
        "    total_occurrences = sum(y_counter.values())\n",
        "    entropy = 0.0\n",
        "    for xy in xy_counter.keys():\n",
        "        p_xy = xy_counter[xy] / total_occurrences\n",
        "        p_y = y_counter[xy[1]] / total_occurrences\n",
        "        entropy += p_xy * math.log(p_y / p_xy, log_base)\n",
        "    return entropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLzxXJhqGWxf"
      },
      "source": [
        "def theils_u(x,\n",
        "             y,\n",
        "             nan_strategy=_REPLACE,\n",
        "             nan_replace_value=_DEFAULT_REPLACE_VALUE):\n",
        "    \"\"\"\n",
        "    Calculates Theil's U statistic (Uncertainty coefficient) for categorical-\n",
        "    categorical association. This is the uncertainty of x given y: value is\n",
        "    on the range of [0,1] - where 0 means y provides no information about\n",
        "    x, and 1 means y provides full information about x.\n",
        "    This is an asymmetric coefficient: U(x,y) != U(y,x)\n",
        "    Wikipedia: https://en.wikipedia.org/wiki/Uncertainty_coefficient\n",
        "    Parameters:\n",
        "    -----------\n",
        "    x : list / NumPy ndarray / Pandas Series\n",
        "        A sequence of categorical measurements\n",
        "    y : list / NumPy ndarray / Pandas Series\n",
        "        A sequence of categorical measurements\n",
        "    nan_strategy : string, default = 'replace'\n",
        "        How to handle missing values: can be either 'drop' to remove samples\n",
        "        with missing values, or 'replace' to replace all missing values with\n",
        "        the nan_replace_value. Missing values are None and np.nan.\n",
        "    nan_replace_value : any, default = 0.0\n",
        "        The value used to replace missing values with. Only applicable when\n",
        "        nan_strategy is set to 'replace'.\n",
        "    Returns:\n",
        "    --------\n",
        "    float in the range of [0,1]\n",
        "    \"\"\"\n",
        "    if nan_strategy == _REPLACE:\n",
        "        x, y = replace_nan_with_value(x, y, nan_replace_value)\n",
        "    elif nan_strategy == _DROP:\n",
        "        x, y = remove_incomplete_samples(x, y)\n",
        "    s_xy = conditional_entropy(x, y)\n",
        "    x_counter = Counter(x)\n",
        "    total_occurrences = sum(x_counter.values())\n",
        "    p_x = list(map(lambda n: n / total_occurrences, x_counter.values()))\n",
        "    s_x = ss.entropy(p_x)\n",
        "    if s_x == 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return (s_x - s_xy) / s_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDtdAsDtFlBl"
      },
      "source": [
        "Conditional Entropy between 2 features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oFm4HHWGWxg"
      },
      "source": [
        "conditional_entropy(df2['RACE'],df2['HOMEOWNERSHIP_STATUS'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RypQHz4XaxFU"
      },
      "source": [
        "Below is some pseudo-code intended to traverse through all features within the data in order to generate conditional entropy values with other features in the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXV1iNkh_k_d"
      },
      "source": [
        "dictionary = dict()\n",
        "for x in df2.columns:\n",
        "    for y in df2.columns:\n",
        "        dictionary[x + '_' + y] = conditional_entropy(df2[x],df2[y])\n",
        "        print(dictionary[x + '_' + y])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShUr_-wPcDKe"
      },
      "source": [
        "we now know that the categorical data types we have are fit for generating the various metrics, now we put those metrics into a heatmap\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ-1bNL9wS47"
      },
      "source": [
        "# creating a blank correlation matrix of dimension (num_features x num_feautres)\n",
        "rows, cols = (len(df2.columns), len(df2.columns))\n",
        "corra_matrix = [[0]*cols]*rows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G73KJJCob7SD"
      },
      "source": [
        "#populating the correlation matrix with our correlation metric of choice, in this case, conditional entropy\n",
        "i = 0\n",
        "for x in df2.columns:\n",
        "    j = 0\n",
        "    for y in df2.columns:\n",
        "        \n",
        "        corra_matrix [i][j]= conditional_entropy(df2[x],df2[y])\n",
        "        j+=1\n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUXiC-H4xXra"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A34xBhFh-NB"
      },
      "source": [
        "Resources: \n",
        "\n",
        "\n",
        "\n",
        "1.   https://towardsdatascience.com/the-search-for-categorical-correlation-a1cf7f1888c9\n",
        "\n",
        "2.   https://github.com/shakedzy/dython/blob/master/dython/nominal.py\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6vSMQ9tii7w"
      },
      "source": [
        "Author(s): Wei Dai, Sam Stilson, Michelle Gu, Lubah Nelson, Noor-Ul-Ain Ali"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0SlyAKWjBVr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "bf170ebb114d4b7d97aba697af3aa9d5",
            "844bd6b0532940a5bb7587250110f241",
            "90fdd06faf824e1caba936490b811ef0"
          ]
        },
        "outputId": "99f87fce-e50f-42c9-b5be-60ac450743cf"
      },
      "source": [
        "widgets.IntSlider()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf170ebb114d4b7d97aba697af3aa9d5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "IntSlider(value=0)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GaNPH-jrtxD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}